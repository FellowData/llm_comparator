# ğŸ¤– LLM Comparator App

This Streamlit app allows you to **compare responses from multiple LLMs** (Large Language Models) including Mistral, LLaMA, Gemma, DeepSeek, and OpenAIâ€™s GPT-4o, all from a single interface.

---

## ğŸš€ Features

- ğŸ§  Multi-model API support: OpenRouter, Claude, Perplexity, Gemini, Mistral, Deepseek, ChatGPT
- ğŸ’¬ Prompt input with source-tracking instruction
- ğŸ“Š Compare responses across models
- ğŸ›¡ï¸ Graceful error handling (e.g. 503 fallback)
- ğŸ“œ Prompt history stored as JSON
- ğŸ” Filters for prompts tab and prompts history
- ğŸ“¤ Export prompt history as Excel file
- ğŸ” Secure API key usage via Streamlit Secrets
- Architecture modulaire : SÃ©paration claire des responsabilitÃ©s
- Pattern Adapter : ExtensibilitÃ© pour nouveaux providers
- Fallback robuste : Double persistance (cloud + local)
- Configuration externalisÃ©e : YAML pour les modÃ¨les
---

## ğŸ›  Installation

```bash
git clone https://github.com/your-username/llm-comparator.git
cd llm-comparator
pip install -r requirements.txt
streamlit run app.py
```

### ğŸ“¦ Requirements
- See requirements.txt
    - `pandas` for prompt history handling
    - `openpyxl` to support Excel export
- Account with API on [openrouter.ai](https://openrouter.ai) to use free/paid LLMs:
    1. Sign up on https://openrouter.ai
    2. Go to profile > API Key
    3. Copy the key and add it to secrets (see below)
- Identify which LLMs to use for free with Openrouter : https://openrouter.ai/models

- Account with API access to [OpenAI](https://platform.openai.com)
- Check your spending on https://platform.openai.com/settings/organization/usage
- It is also possible to define a project with spending limits : https://help.openai.com/en/articles/9186755-managing-projects-in-the-api-platform#h_d2c8f84ece
---


## ğŸ” Configuration

Create a `.streamlit/secrets.toml` file:

```toml
OPENROUTER_API_KEY = "pk-..."
OPENAI_API_KEY = "sk-..."
...
```

Or, use Streamlit Cloud's **Secrets Manager** if deployed online.


Create a Database on https://supabase.com

---

## ğŸ“œ Prompt History

Prompts are stored on a distant database (supabase) and locally in `prompt_history.json` with:

- Timestamp
- Prompt content
- Model name and ID
- Raw model response

The app includes:
- A history viewer tab
- Filter by model
- Search prompt text
- Search answer text
- Excel download (`prompt_history.xlsx`)

---

## ğŸš€ Deployment

### Option 1: Local

```bash
streamlit run app.py
```

### Option 2: Streamlit Community Cloud

- GitHub repo required
- Set secrets via the web UI
- Deploy in one click: https://streamlit.io/cloud
- App should be available through https://share.streamlit.io/
---

## ğŸ§± Tech Stack

- Python 3.11+
- Streamlit
- OpenRouter API
- OpenAI SDK
- pandas + openpyxl (for Excel export)

---

## ğŸ“„ License

MIT