import streamlit as st
import requests
from openai import OpenAI

# üîê Cl√© API OpenAI (direct)
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

API_URL = "https://openrouter.ai/api/v1/chat/completions"
HEADERS = {
    "Authorization": f"Bearer {st.secrets['OPENROUTER_API_KEY']}",
    "Content-Type": "application/json"
}

AVAILABLE_MODELS = {
    "Mistral: Mistral Small 3.2 24B (free) üü¢": "mistralai/mistral-small-3.2-24b-instruct:free",
    "Meta: Llama 3.3 70B Instruct (free) üîµ": "meta-llama/llama-3.3-70b-instruct:free",
    "Google: Gemma 3n 2B (free) üü£": "google/gemma-3n-e2b-it:free",
    "DeepSeek: R1 0528 (free) üü†": "deepseek/deepseek-r1-0528:free",
    "OpenAI: gpt-4.1-mini üß†": "gpt-4.1-nano",  # Ajout√©
}

st.title("üß† Comparateur de LLMs via OpenRouter + OpenAI")

prompt = st.text_area("üí¨ Ton prompt ici :", height=150)
selected = st.multiselect("S√©lectionne un ou plusieurs mod√®les :", list(AVAILABLE_MODELS.keys()), default=list(AVAILABLE_MODELS.keys())[:2])

if st.button("üöÄ Lancer la requ√™te") and prompt and selected:
    for name in selected:
        model_id = AVAILABLE_MODELS[name]
        st.markdown(f"### ü§ñ {name}")
        with st.spinner("R√©ponse en cours..."):
            instruction = (
                "√Ä la fin de ta r√©ponse, ajoute une section intitul√©e '=== SOURCES ===' "
                "avec la liste des urls des sites web utilis√©es pour la r√©ponse."
            )

            full_prompt = f"{prompt.strip()}\n\n{instruction}"

            try:
                if model_id.startswith("gpt-"):
                    if not client.api_key:
                        st.error("Cl√© OPENAI_API_KEY manquante dans les secrets Streamlit.")
                        continue

                    response = client.chat.completions.create(
                        model=model_id,  # ou extraire dynamiquement
                        messages=[{"role": "user", "content": full_prompt}],
                        temperature=0.7,
                        max_tokens=1024,
                    )
                    content = response.choices[0].message.content

                else:
                    payload = {
                        "model": model_id,
                        "messages": [{"role": "user", "content": full_prompt}]
                    }
                    response = requests.post(API_URL, headers=HEADERS, json=payload)

                    if response.status_code != 200:
                        st.error(f"Erreur HTTP {response.status_code} : {response.text}")
                        continue

                    data = response.json()
                    if "choices" not in data:
                        st.error(f"Erreur API OpenRouter : {data}")
                        continue

                    content = data["choices"][0]["message"]["content"]

                st.success("R√©ponse re√ßue")
                if "=== SOURCES ===" in content:
                    answer_part, sources_part = content.split("=== SOURCES ===", 1)
                else:
                    answer_part = content
                    sources_part = "*Aucune source identifiable fournie.*"

                st.markdown("**üìù R√©ponse :**")
                st.write(answer_part.strip())

                st.markdown("**üîó Sources :**")
                st.info(sources_part.strip())

            except Exception as e:
                st.error(f"Erreur : {e}")
