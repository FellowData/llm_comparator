#!/usr/bin/env python3
"""
Script de test pour l'Ã©valuateur de rÃ©ponses
VÃ©rifie que tout fonctionne correctement
"""

from response_evaluator import ResponseEvaluator, count_syllables, simple_flesch_reading_ease

def test_syllable_counter():
    """Test du compteur de syllabes"""
    print("ðŸ”¤ Test du compteur de syllabes:")
    test_words = [
        ("hello", 2),
        ("world", 1), 
        ("artificial", 4),
        ("intelligence", 4),
        ("Ã©valuation", 5),
        ("franÃ§ais", 2)
    ]
    
    for word, expected in test_words:
        result = count_syllables(word)
        status = "âœ…" if abs(result - expected) <= 1 else "âŒ"  # TolÃ©rance de Â±1
        print(f"  {status} '{word}': {result} syllabes (attendu: ~{expected})")

def test_readability():
    """Test du score de lisibilitÃ©"""
    print("\nðŸ“– Test du score de lisibilitÃ©:")
    
    texts = [
        ("Texte trÃ¨s simple. Mots courts. Phrases courtes.", "Facile"),
        ("Ce texte prÃ©sente une complexitÃ© intermÃ©diaire avec des phrases de longueur moyenne.", "Standard"),
        ("Cette dÃ©monstration illustre la mÃ©thodologie d'Ã©valuation algorithmique sophistiquÃ©e.", "Difficile")
    ]
    
    for text, expected_level in texts:
        score = simple_flesch_reading_ease(text)
        print(f"  ðŸ“ Score: {score:.1f} - Texte: {text[:50]}...")

def test_full_evaluation():
    """Test complet de l'Ã©valuateur"""
    print("\nðŸ”¬ Test complet de l'Ã©valuateur:")
    
    evaluator = ResponseEvaluator()
    
    # Test avec une rÃ©ponse simulÃ©e
    prompt = "Expliquez-moi les avantages de l'intelligence artificielle"
    response = """L'intelligence artificielle prÃ©sente plusieurs avantages majeurs :

1. **Automatisation** : Elle permet d'automatiser des tÃ¢ches rÃ©pÃ©titives
2. **Analyse de donnÃ©es** : Traitement rapide de grandes quantitÃ©s d'information
3. **PrÃ©cision** : RÃ©duction des erreurs humaines

En conclusion, l'IA transforme notre faÃ§on de travailler.

=== SOURCES ===
https://fr.wikipedia.org/wiki/Intelligence_artificielle
https://www.lemonde.fr/intelligence-artificielle/
https://www.nature.com/subjects/machine-learning
"""
    
    result = evaluator.evaluate_response(prompt, response, "Test Model")
    
    print(f"  ðŸŽ¯ Score Global: {result.overall_score}/10")
    print(f"  ðŸ“– LisibilitÃ©: {result.readability_score}/10")
    print(f"  ðŸ—ï¸ Structure: {result.structure_score}/10")
    print(f"  ðŸ”— Sources: {result.sources_score}/10")
    print(f"  ðŸ“‹ ComplÃ©tude: {result.completeness_score}/10")
    print(f"  ðŸŽ¯ Pertinence: {result.relevance_score}/10")
    
    print(f"\nðŸ’¡ Recommandations:")
    for rec in result.recommendations[:2]:  # Afficher les 2 premiÃ¨res
        print(f"  â€¢ {rec}")

def test_edge_cases():
    """Test des cas limites"""
    print("\nâš ï¸ Test des cas limites:")
    
    evaluator = ResponseEvaluator()
    
    # RÃ©ponse vide
    result = evaluator.evaluate_response("Test prompt", "", "Empty Model")
    print(f"  ðŸ“­ RÃ©ponse vide - Score: {result.overall_score}/10")
    
    # RÃ©ponse trÃ¨s courte
    result = evaluator.evaluate_response("Test prompt", "Oui.", "Short Model")
    print(f"  ðŸ“ RÃ©ponse courte - Score: {result.overall_score}/10")
    
    # RÃ©ponse sans sources
    result = evaluator.evaluate_response("Test prompt", "Une rÃ©ponse normale sans sources.", "No Sources Model")
    print(f"  ðŸš« Sans sources - Score: {result.overall_score}/10")

if __name__ == "__main__":
    print("ðŸ§ª Test de l'Ã‰valuateur de RÃ©ponses LLM")
    print("=" * 50)
    
    try:
        test_syllable_counter()
        test_readability()
        test_full_evaluation()
        test_edge_cases()
        
        print("\n" + "=" * 50)
        print("âœ… Tous les tests sont passÃ©s avec succÃ¨s!")
        print("ðŸš€ L'Ã©valuateur est prÃªt Ã  Ãªtre utilisÃ©!")
        
    except Exception as e:
        print(f"\nâŒ Erreur lors des tests: {e}")
        print("ðŸ”§ VÃ©rifiez que response_evaluator.py est dans le mÃªme dossier")